{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO FILL WITH MANUALLY FILLED DATA\n",
    "\n",
    "import pandas as pd\n",
    "filled = pd.read_csv(\"manual_filled.csv\")\n",
    "people = pd.read_csv(\"final/people.csv\")\n",
    "contacts = pd.read_csv(\"final/contacts.csv\")\n",
    "for index, row in filled.iterrows():\n",
    "    \"id,Assigned,first_name,last_name,gender,class_year,is_jewish,school,contacts,\"\n",
    "    person_id = int(row['id'])\n",
    "    person_index = people.index[people['id'] == person_id].tolist()[0]\n",
    "    people.at[person_index, 'first_name'] = row['first_name']\n",
    "    people.at[person_index, 'last_name'] = row['last_name']\n",
    "    people.at[person_index, 'gender'] = row['gender']\n",
    "    people.at[person_index, 'class_year'] = row['class_year']\n",
    "    people.at[person_index, 'is_jewish'] = row['is_jewish']\n",
    "    people.at[person_index, 'school'] = row['school']\n",
    "\n",
    "    contact = row['contacts']\n",
    "    if pd.isna(contact):\n",
    "        continue\n",
    "    contact = contact.strip().lower()\n",
    "    if contact not in contacts['contact_value']:\n",
    "        contact_id = contacts['id'].max() + 1\n",
    "        contact_type = \"school email\" if contact.endswith(\"@college.harvard.edu\") or contact.endswith(\"@mit.edu\") else \"personal email\"\n",
    "        contacts.loc[len(contacts)] = [contact_id, person_id, contact_type, contact, False]\n",
    "    else:\n",
    "        existing_contact = contacts[contacts['contact_value'] == contact]\n",
    "        existing_person_id = existing_contact['person_id'].values[0]\n",
    "        if existing_person_id != person_id:\n",
    "            print(f\"Contact {contact} is linked to person {existing_person_id} but should be linked to {person_id}\")\n",
    "\n",
    "people.to_csv(\"final/people.csv\", index=False)\n",
    "contacts.to_csv(\"final/contacts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = pd.read_csv(\"final/people.csv\")\n",
    "contacts = pd.read_csv(\"final/contacts.csv\")\n",
    "\n",
    "# contacts onto to people m:1\n",
    "# create one row per person with contacts as a list of the contact_value column values\n",
    "contacts_grouped = contacts[contacts['contact_type'] == \"school email\"].groupby(\"person_id\")[\"contact_value\"].first().reset_index()\n",
    "people = people.merge(contacts_grouped, left_on=\"id\", right_on=\"person_id\", how=\"left\")\n",
    "people.rename(columns={\"contact_value\": \"contacts\"}, inplace=True)\n",
    "people.drop(columns=[\"person_id\", \"preferred_name\"], inplace=True)\n",
    "\n",
    "# find any null values unless school = Other, then class year can be null and school email can be null\n",
    "to_fill = people[people[\"school\"] != \"Other\"]\n",
    "to_fill = to_fill[to_fill.isna().any(axis=1)]\n",
    "to_fill_other = people[people[\"school\"] == \"Other\"]\n",
    "to_fill_other = to_fill_other[to_fill_other[[\"first_name\", \"last_name\", \"gender\", \"is_jewish\", \"school\"]].isna().any(axis=1)]\n",
    "\n",
    "to_fill = pd.concat([to_fill, to_fill_other])\n",
    "to_fill.drop_duplicates(inplace=True)\n",
    "\n",
    "to_fill[\"class_year\"] = to_fill[\"class_year\"].apply(lambda x: pd.NA if pd.isna(x) else int(x))\n",
    "to_fill.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill.to_csv(\"to_fill.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# add is first event\n",
    "import pandas as pd\n",
    "\n",
    "# Load RSVPs CSV\n",
    "attendance = pd.read_csv('final/attendance.csv').iloc[:, 1:]\n",
    "attendance[\"approved\"] = attendance[\"approved\"].astype(bool)\n",
    "# Load Events CSV\n",
    "events = pd.read_csv('final/events.csv')\n",
    "\n",
    "# Add is_first_event column to attendance\n",
    "attendance = attendance.merge(events[['id', 'start_datetime']], left_on='event_id', right_on='id', how='left')\n",
    "\n",
    "# Drop the duplicate 'id' column from events table\n",
    "attendance.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Convert start_datetime to datetime type\n",
    "attendance['start_datetime'] = pd.to_datetime(attendance['start_datetime'])\n",
    "\n",
    "# Sort RSVPs by person_id and event start time\n",
    "attendance_sorted = attendance.sort_values(by=['person_id', 'start_datetime'])\n",
    "first_event_times = attendance_sorted[attendance_sorted['checked_in'] == True]\n",
    "# For each person_id, get the earliest start_datetime (unique pair)\n",
    "first_event_times = first_event_times.groupby('person_id', as_index=False)['start_datetime'].min()\n",
    "\n",
    "\n",
    "attendance_sorted['key'] = attendance_sorted['person_id'].astype(str) + attendance_sorted['start_datetime'].astype(str)\n",
    "first_event_times['key'] = first_event_times['person_id'].astype(str) + first_event_times['start_datetime'].astype(str)\n",
    "# Set is_first_event = True if this is the earliest event, else False\n",
    "attendance_sorted['is_first_event'] = attendance_sorted['key'].isin(first_event_times['key'])\n",
    "attendance_sorted.drop(columns=['key'], inplace=True)\n",
    "attendance_sorted.sort_values(by=['start_datetime'], inplace=True)\n",
    "attendance_sorted.drop(columns=['start_datetime'], inplace=True)\n",
    "\n",
    "attendance = attendance_sorted\n",
    "\n",
    "events = pd.read_csv(\"final/events.csv\")\n",
    "people = pd.read_csv(\"final/people.csv\")\n",
    "\n",
    "attendance = attendance.merge(people, left_on=\"person_id\", right_on=\"id\", how=\"left\")\n",
    "\n",
    "# Standardize data\n",
    "attendance[\"is_jewish\"] = attendance[\"is_jewish\"].apply(lambda x: x if pd.isna(x) else x.upper())\n",
    "attendance[\"gender\"] = attendance[\"gender\"].apply(lambda x: x if pd.isna(x) else x.upper())\n",
    "\n",
    "# Aggregate RSVP, Approved, Checked-in counts by event\n",
    "agg_attendance = attendance.groupby(\"event_id\").agg({\n",
    "    \"rsvp\": \"sum\",\n",
    "    \"approved\": \"sum\",\n",
    "    \"checked_in\": \"sum\",\n",
    "    \"is_first_event\": \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "attendance['is_jewish'] = attendance['is_jewish'].fillna(\"N/A\")\n",
    "attendance['gender'] = attendance['gender'].fillna(\"N/A\")\n",
    "attendance['class_year'] = attendance['class_year'].fillna(1000)\n",
    "# Calculate Jewish status percentages by event\n",
    "jewish_counts = attendance.pivot_table(index=\"event_id\", columns=\"is_jewish\", aggfunc=\"size\")\n",
    "jewish_percentages = jewish_counts.div(jewish_counts.sum(axis=1), axis=0).reset_index()\n",
    "\n",
    "# Calculate Gender percentages by event\n",
    "gender_counts = attendance.pivot_table(index=\"event_id\", columns=\"gender\", aggfunc=\"size\")\n",
    "gender_percentages = gender_counts.div(gender_counts.sum(axis=1), axis=0).reset_index()\n",
    "\n",
    "# Calculate Class year percentages by event\n",
    "class_year_counts = attendance.pivot_table(index=\"event_id\", columns=\"class_year\", aggfunc=\"size\")\n",
    "class_year_percentages = class_year_counts.div(class_year_counts.sum(axis=1), axis=0).reset_index()\n",
    "\n",
    "# Combine all summaries\n",
    "summary = agg_attendance \\\n",
    "    .merge(jewish_percentages, on=\"event_id\", how=\"left\", suffixes=(None, '_jewish')) \\\n",
    "    .merge(gender_percentages, on=\"event_id\", how=\"left\", suffixes=(None, '_gender')) \\\n",
    "    .merge(class_year_percentages, on=\"event_id\", how=\"left\", suffixes=(None, '_class_year'))\n",
    "\n",
    "# Merge with event details (assuming you need event code)\n",
    "final_summary = summary.merge(events[[\"id\", \"category\", \"description\"]], left_on=\"event_id\", right_on=\"id\", how=\"left\")\n",
    "\n",
    "# Drop redundant 'id' column after merge\n",
    "final_summary = final_summary.drop(columns=['id'])\n",
    "\n",
    "\n",
    "final_summary[\"J\"] = final_summary[\"J\"].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else pd.NA)\n",
    "final_summary[\"N\"] = final_summary[\"N\"].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else pd.NA)\n",
    "final_summary[\"F\"] = final_summary[\"F\"].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else pd.NA)\n",
    "final_summary[\"M\"] = final_summary[\"M\"].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else pd.NA)\n",
    "final_summary[2025.0] = final_summary[2025.0].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else pd.NA)\n",
    "final_summary[2026.0] = final_summary[2026.0].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else pd.NA)\n",
    "final_summary[2027.0] = final_summary[2027.0].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else pd.NA)\n",
    "final_summary[2028.0] = final_summary[2028.0].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else pd.NA)\n",
    "final_summary.drop(columns=[\"event_id\"], inplace=True)\n",
    "final_summary.drop(columns=[\"N/A\", \"N/A_gender\", 1000.0], inplace=True)\n",
    "final_summary = final_summary[[\"category\", \"description\", \"rsvp\", \"approved\", \"checked_in\", \"is_first_event\", \"J\", \"N\", \"F\", \"M\", 2025.0, 2026.0, 2027.0, 2028.0]]\n",
    "final_summary.to_excel(\"final_summary.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Email List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate = False\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "people   = pd.read_csv(\"final/people.csv\")\n",
    "contacts = pd.read_csv(\"final/contacts.csv\")\n",
    "attendance  = pd.read_csv(\"final/attendance.csv\")\n",
    "\n",
    "# 1) pick out subsets\n",
    "school_emails = contacts[contacts[\"contact_type\"] == \"school email\"]\n",
    "all_emails    = contacts[contacts[\"contact_type\"].str.contains(\"email\", na=False)]\n",
    "\n",
    "# 2) assemble with priority tags\n",
    "group1 = (\n",
    "    people\n",
    "    .merge(school_emails, left_on=\"id\", right_on=\"person_id\", how=\"inner\")\n",
    "    .assign(priority=1)\n",
    ")\n",
    "group2 = (\n",
    "    people[people[\"school\"].str.lower() == \"harvard\"]\n",
    "    .merge(all_emails, left_on=\"id\", right_on=\"person_id\", how=\"left\")\n",
    "    .assign(priority=2)\n",
    ")\n",
    "group3 = (\n",
    "    people[people[\"school\"].str.lower() == \"mit\"]\n",
    "    .merge(all_emails, left_on=\"id\", right_on=\"person_id\", how=\"left\")\n",
    "    .assign(priority=3)\n",
    ")\n",
    "group4 = (\n",
    "    people\n",
    "    .merge(all_emails, left_on=\"id\", right_on=\"person_id\", how=\"inner\")\n",
    "    .query(\"school.str.lower() not in ['mit','harvard']\")\n",
    "    .query(\"not contact_value.str.endswith('berklee.edu')\")\n",
    "    .assign(priority=4)\n",
    ")\n",
    "\n",
    "# 3) concat + dedupe on person_id\n",
    "all_people = pd.concat([group1, group2, group3, group4], ignore_index=True)\n",
    "all_people = (\n",
    "    all_people\n",
    "    .sort_values(\"priority\")\n",
    "    .drop_duplicates(subset=[\"person_id\"], keep=\"first\")\n",
    ")\n",
    "\n",
    "attendance = attendance[attendance[\"checked_in\"] == True]\n",
    "event_counts = attendance.groupby(\"person_id\")[\"id\"].count().reset_index()\n",
    "event_counts.rename(columns={\"id\": \"event_count\"}, inplace=True)\n",
    "\n",
    "all_people = all_people.merge(event_counts, left_on=\"person_id\", right_on=\"person_id\", how=\"left\")\n",
    "all_people.drop(columns=[\"person_id\"], inplace=True)\n",
    "\n",
    "all_people['event_count'] = all_people['event_count'].fillna(0)\n",
    "\n",
    "# 4) keep only the columns you need\n",
    "all_people = all_people[[\"first_name\", \"last_name\", \"school\", \"contact_value\", \"event_count\"]]\n",
    "\n",
    "if separate:\n",
    "    # 5) split MIT vs others with a consistent boolean mask\n",
    "    mask_mit = (\n",
    "        all_people[\"school\"].str.lower().eq(\"mit\")\n",
    "        | all_people[\"contact_value\"].str.endswith(\"mit.edu\")\n",
    "    )\n",
    "    mit   = all_people[mask_mit].copy()\n",
    "    other = all_people[~mask_mit].copy()\n",
    "\n",
    "    # 6) write out\n",
    "    mit.to_csv(\"mit_mailing.csv\",        index=False)\n",
    "    other.to_csv(\"zakarias_mailing.csv\", index=False)\n",
    "else:\n",
    "    # 5) write out\n",
    "    all_people.to_csv(\"all_mailing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
